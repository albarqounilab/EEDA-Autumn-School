{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882ab959",
   "metadata": {},
   "source": [
    "# Understanding Feature Extraction and Convolution in Computer Vision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05439c9d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we will explore the concept of feature extraction using the convolution operation in PyTorch, a popular deep learning framework. Feature extraction is a critical step in computer vision tasks, where we aim to extract meaningful patterns or features from images that can be used for various tasks like object detection, image recognition, and more.\n",
    "\n",
    "### Table of Contents\n",
    "1. Introduction to Convolution and Feature Extraction\n",
    "\n",
    "2. Convolution in PyTorch\n",
    "\n",
    "    2.1 Importing Necessary Packages\n",
    "    \n",
    "    2.2 Creating the Input Matrix\n",
    "    \n",
    "    2.3 Defining the Custom Convolutional Kernel\n",
    "    \n",
    "    2.4 Performing Element-wise Multiplication\n",
    "    \n",
    "    2.5 Calculating the Convolution Output\n",
    "    \n",
    "    2.6 Example: Convolving a Sunflower Image\n",
    "    \n",
    "3. Creating a Filter for Edge Detection\n",
    "\n",
    "    3.1 Importing Resources and Displaying the Image\n",
    "    \n",
    "    3.2 Converting the Image to Grayscale\n",
    "    \n",
    "    3.3 Creating and Applying a Sobel X Operator\n",
    "    \n",
    "    3.4 Testing Other Filters\n",
    "\n",
    "Exercise: Custom Kernel for Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008cdff9",
   "metadata": {},
   "source": [
    "## 1. Introduction to Convolution and Feature Extraction\n",
    "Convolution is a fundamental operation in deep learning, especially in convolutional neural networks (CNNs), used extensively in computer vision tasks. It involves sliding a small filter (also called a kernel) over an input matrix, performing element-wise multiplication and summation to produce a new output matrix called the feature map. The feature map represents the response of the filter to different patterns in the input matrix.\n",
    "\n",
    "Feature extraction using convolution helps identify important patterns, edges, and textures in an image. These extracted features are then used as inputs for higher-level tasks, such as image classification or object detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619fecad",
   "metadata": {},
   "source": [
    "## 2. Convolution in PyTorch\n",
    "### 2.1 Importing Necessary Packages\n",
    "Let's start by importing the required libraries and packages for the first part of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d683e77",
   "metadata": {},
   "source": [
    "## 2.2 Creating the Input Matrix\n",
    "We will create a 3x3 input matrix (A) that we want to convolve with a custom kernel later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float32)\n",
    "print(A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e721767b",
   "metadata": {},
   "source": [
    "### 2.3 Defining the Custom Convolutional Kernel\n",
    "Now, let's define the convolutional kernel (B) that will be used to convolve with the input matrix (A). The values of this kernel will be manually set for edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.tensor([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], dtype=torch.float32)\n",
    "print(B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ed04d",
   "metadata": {},
   "source": [
    "### 2.4 Performing Element-wise Multiplication\n",
    "The first step of the convolution operation is to perform element-wise multiplication between the input matrix (A) and the convolutional kernel (B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a867ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_out = torch.mul(A, B)\n",
    "print(mult_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d670818d",
   "metadata": {},
   "source": [
    "### 2.5 Calculating the Convolution Output\n",
    "The second step is to sum the elements of the result obtained from the element-wise multiplication. The resulting single value represents the convolved output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36dd25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_out = torch.sum(mult_out)\n",
    "print(conv_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f5fc29",
   "metadata": {},
   "source": [
    "### 2.6 Example: Convolving a Sunflower Image\n",
    "In this section, we will convolve a real sunflower image using the same 3x3 kernel (B) for edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the sunflower image\n",
    "image = cv2.imread('02.1_sunflower_image.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Apply the convolution...\n",
    "img = cv2.filter2D(image, -1, B.numpy())\n",
    "\n",
    "# Display the original and convolved images side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(24, 16))\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(img)\n",
    "ax[1].set_title('Convolved Image')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d14a80",
   "metadata": {},
   "source": [
    "## 3. Creating a Filter for Edge Detection\n",
    "In this section, we will explore edge detection using a Sobel filter. The Sobel filter is commonly used in edge detection and helps identify edges and gradients in an image.\n",
    "3.1 Importing Resources and Displaying the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3027b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image_path = '02.1_sunflower_image.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Display the original and grayscale images\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718421a8",
   "metadata": {},
   "source": [
    "3.3 Creating and Applying a Sobel X Operator\n",
    "Now, we'll create a custom Sobel X operator and apply it to the grayscale image to detect edges in the x-direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b3e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Sobel x operator\n",
    "sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "\n",
    "# Convert the Sobel x operator to a PyTorch tensor\n",
    "sobel_x = torch.tensor(sobel_x, dtype=torch.float32)\n",
    "\n",
    "# Apply the convolution using filter2D\n",
    "filtered_image = cv2.filter2D(gray, -1, sobel_x.numpy())\n",
    "\n",
    "# Display the filtered image\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(filtered_image, cmap='gray')\n",
    "plt.title('Filtered Image (Sobel x)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de1efa6",
   "metadata": {},
   "source": [
    "### 3.4 Testing Other Filters\n",
    "Feel free to create and test other filters to see different effects on the image. For example, you can create filters with decimal value weights or try a 5x5 filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c161a3",
   "metadata": {},
   "source": [
    "## 4. Exercise: Custom Kernel for Feature Extraction\n",
    "For this exercise, you'll define your custom kernel to perform feature extraction. Experiment with different kernel values to see how they affect the feature map. Ensure that the sum of the kernel values is between 0 and 1 for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd874b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom kernel with 3 rows and 3 columns\n",
    "# kernel = torch.tensor(...], dtype=torch.float32)\n",
    "\n",
    "# Display the kernel\n",
    "# print(kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd5123",
   "metadata": {},
   "source": [
    "Now, let's define our custom filters for edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d548fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom edge detection filter with decimal value weights\n",
    "# custom_filter_decimal = np.array([])\n",
    "\n",
    "# Custom 5x5 edge detection filter\n",
    "# custom_filter_5x5 = np.array([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a8e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "# image_path = ''\n",
    "# image = cv2.imread(image_path)\n",
    "\n",
    "# Define the custom filters as PyTorch tensors\n",
    "# custom_filter_decimal = torch.tensor(...)\n",
    "# custom_filter_5x5 = torch.tensor(...)\n",
    "\n",
    "# Apply the custom filters using filter2D\n",
    "# filtered_image_decimal = cv2.filter2D()\n",
    "# filtered_image_5x5 = cv2.filter2D()\n",
    "\n",
    "# Display the original and filtered images\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.subplot(1, 3, 1)\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45683f85",
   "metadata": {},
   "source": [
    "After defining the kernel, you'll apply it to the given image using convolution and visualize the resulting feature map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29685059",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "In this notebook, we explored the concepts of feature extraction and convolution in computer vision. We learned how to perform convolution using PyTorch and applied custom kernels for feature extraction. Understanding feature extraction is crucial for building effective computer vision models and can be a stepping stone for more complex tasks like object detection and segmentation. Experimenting with different kernels allows us to extract specific patterns and information from images, enabling us to gain insights and make better decisions in various applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1257399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
