{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNNs Applications\n",
        "Convolutional Neural Networks (CNNs) have revolutionized the world of image processing and computer vision. you can explore interactive playgrounds and applications that showcase their remarkable capabilities. let's dive in a couple of examples to understand what CNNs can do:\n",
        "\n",
        "Playgrounds:\n",
        "\n",
        "- [Image Convolution Playground](https://generic-github-user.github.io/Image-Convolution-Playground/src/) Experiment with complex image processing operations in your browser.\n",
        "- [CNN vision](https://adamharley.com/nn_vis/cnn/2d.html) Draw numbers and inspect layers.\n",
        "- [Image kernels](https://setosa.io/ev/image-kernels/) Image Kernels\n",
        "Explained Visually\n",
        "- [Image Convolution Playground](https://generic-github-user.github.io/Image-Convolution-Playground/src/) Experiment with complex image processing operations in your browser.\n",
        "\n",
        "Play with CNNs:\n",
        "\n",
        "- [Quick draw](https://quickdraw.withgoogle.com) Play pictionary with a CNN!\n",
        "- [AutoDraw](https://www.autodraw.com/) CNN helps you draw!"
      ],
      "metadata": {
        "id": "TLHGSzL2JvTz"
      },
      "id": "TLHGSzL2JvTz"
    },
    {
      "cell_type": "markdown",
      "id": "b97c9bec",
      "metadata": {
        "id": "b97c9bec"
      },
      "source": [
        "# Understanding Feature Extraction and Convolution in Computer Vision (40-60 min)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b00f9950",
      "metadata": {
        "id": "b00f9950"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this notebook, we will explore the concept of feature extraction using the convolution operation in PyTorch, a popular deep learning framework. Feature extraction is a critical step in computer vision tasks, where we aim to extract meaningful patterns or features from images that can be used for various tasks like object detection, image recognition, and more.\n",
        "\n",
        "### Table of Contents\n",
        "1. Introduction to Convolution and Feature Extraction\n",
        "\n",
        "2. Convolution in PyTorch\n",
        "\n",
        "    2.1 Importing Necessary Packages\n",
        "    \n",
        "    2.2 Creating the Input Matrix\n",
        "    \n",
        "    2.3 Defining the Custom Convolutional Kernel\n",
        "    \n",
        "    2.4 Performing Element-wise Multiplication\n",
        "    \n",
        "    2.5 Calculating the Convolution Output\n",
        "    \n",
        "    2.6 Example: Convolving a Sunflower Image\n",
        "    \n",
        "3. Creating a Filter for Edge Detection\n",
        "\n",
        "    3.1 Importing Resources and Displaying the Image\n",
        "    \n",
        "    3.2 Converting the Image to Grayscale\n",
        "    \n",
        "    3.3 Creating and Applying a Sobel X Operator\n",
        "    \n",
        "    3.4 Testing Other Filters\n",
        "\n",
        "Exercise: Custom Kernel for Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1836895f",
      "metadata": {
        "id": "1836895f"
      },
      "source": [
        "## 1. Introduction to Convolution and Feature Extraction (10 min)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN'S are a way to recognize objects and images in images or video:\n",
        "<img src=\"https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/c9404fc86181fc3f0906b368697268257f348535/convolutional-neural-networks/conv-visualization/notebook_ims/conv_layer.gif\" width=\"600\">\n",
        "\n",
        ">  Convolution is a fundamental operation in deep learning, especially in convolutional neural networks (CNNs), used extensively in computer vision tasks. It involves sliding a small filter (also called a kernel) over an input matrix, performing element-wise multiplication and summation to produce a new output matrix called the feature map. The feature map represents the response of the filter to different patterns in the input matrix. [1]\n"
      ],
      "metadata": {
        "id": "j9pyRyTzAxyu"
      },
      "id": "j9pyRyTzAxyu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature extraction using convolution helps identify important patterns, edges, and textures in an image. These extracted features are then used as inputs for higher-level tasks, such as image classification or object detection."
      ],
      "metadata": {
        "id": "INs1Nqbu__uh"
      },
      "id": "INs1Nqbu__uh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://developer.nvidia.com/sites/default/files/pictures/2018/convolution-1.png\" width=\"600\">\n",
        "\n",
        "Source: https://developer.nvidia.com/discover/convolution"
      ],
      "metadata": {
        "id": "zEUUINV9DS-A"
      },
      "id": "zEUUINV9DS-A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we talk about the convolution the symbolic architecture depicts the following:\n",
        "\n",
        "<img src=\"https://imgur.com/Q4mMY69.png\" width=\"600\">\n",
        "\n",
        "---\n",
        "\n",
        "**Notations Used**\n",
        "\n",
        "- **X**: Represents the input data, where X = {x₁, x₂, ..., xₙ} ∈ ℝ^(H×W×D×N).\n",
        "- **N**: Denotes the number of input instances or samples.\n",
        "- **H**: Corresponds to the height of an image xᵢ ∈ ℕ, where i ranges from 1 to N.\n",
        "- **W**: Represents the width of an image xᵢ ∈ ℕ.\n",
        "- **D**: Indicates the number of channels or depth of an image/volume xᵢ ∈ ℕ.\n",
        "- **Y**: Signifies the desired output, where Y = {y₁, y₂, ..., yₙ} ∈ ℝ^(c×N), with c being the dimensionality of the output.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BtpL_hNaDg4z"
      },
      "id": "BtpL_hNaDg4z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating a convolution is shown as sliding a part of the original image (dark blue) over the entire original image (blue), performing mathematical operations in matrices. The result is placed in a new image (green cell in the convolved feature), which helps us analyze data and create interesting effects. This process can be made much faster using a special technique called Fast Fourier Transform (FFT), often used in powerful GPUs.\n",
        "\n",
        "![img](https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides.gif)\n",
        "\n",
        "Source image: [2]\n",
        "\n",
        "When we apply the Fourier transform to both the \"kernel\" (like a filter) and the \"feature map\" (like the image), it makes convolution much easier. Instead of complicated math, it becomes a simple multiplication.\n",
        "\n"
      ],
      "metadata": {
        "id": "7QAm__IWG4YF"
      },
      "id": "7QAm__IWG4YF"
    },
    {
      "cell_type": "markdown",
      "id": "7d1a4ab6",
      "metadata": {
        "id": "7d1a4ab6"
      },
      "source": [
        "## 2. Convolution in PyTorch (10 min)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Importing Necessary Packages\n",
        "Let's start by importing the required libraries and packages for the first part of the notebook."
      ],
      "metadata": {
        "id": "blRhc0xuFv49"
      },
      "id": "blRhc0xuFv49"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee833a86",
      "metadata": {
        "id": "ee833a86"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6071dc24",
      "metadata": {
        "id": "6071dc24"
      },
      "source": [
        "### 2.2 Creating the Input Matrix\n",
        "We will create a 3x3 input matrix (A) that we want to convolve with a custom kernel later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f690cc72",
      "metadata": {
        "id": "f690cc72"
      },
      "outputs": [],
      "source": [
        "A = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float32)\n",
        "print(A)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "143ca392",
      "metadata": {
        "id": "143ca392"
      },
      "source": [
        "### 2.3 Defining the Custom Convolutional Kernel\n",
        "Now, let's define the convolutional kernel (B) that will be used to convolve with the input matrix (A). The values of this kernel will be manually set for edge detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f129bae",
      "metadata": {
        "id": "1f129bae"
      },
      "outputs": [],
      "source": [
        "B = torch.tensor([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], dtype=torch.float32)\n",
        "print(B)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8658b3b5",
      "metadata": {
        "id": "8658b3b5"
      },
      "source": [
        "### 2.4 Performing Element-wise Multiplication\n",
        "The first step of the convolution operation is to perform element-wise multiplication between the input matrix (A) and the convolutional kernel (B)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc68d49f",
      "metadata": {
        "id": "dc68d49f"
      },
      "outputs": [],
      "source": [
        "mult_out = torch.mul(A, B)\n",
        "print(mult_out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43d15f82",
      "metadata": {
        "id": "43d15f82"
      },
      "source": [
        "### 2.5 Calculating the Convolution Output\n",
        "The second step is to sum the elements of the result obtained from the element-wise multiplication. The resulting single value represents the convolved output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "097d85c2",
      "metadata": {
        "id": "097d85c2"
      },
      "outputs": [],
      "source": [
        "conv_out = torch.sum(mult_out)\n",
        "print(conv_out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e72a4503",
      "metadata": {
        "id": "e72a4503"
      },
      "source": [
        "### 2.6 Example: Convolving a Sunflower Image\n",
        "In this section, we will convolve a real sunflower image using the same 3x3 kernel (B) for edge detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05f5efa2",
      "metadata": {
        "id": "05f5efa2"
      },
      "outputs": [],
      "source": [
        "# Load and display the sunflower image\n",
        "image = cv2.imread('02.1_sunflower_image.jpg')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Apply the convolution...\n",
        "img = cv2.filter2D(image, -1, B.numpy())\n",
        "\n",
        "# Display the original and convolved images side by side\n",
        "fig, ax = plt.subplots(1, 2, figsize=(24, 16))\n",
        "ax[0].imshow(image)\n",
        "ax[0].set_title('Original Image')\n",
        "ax[0].axis('off')\n",
        "\n",
        "ax[1].imshow(img)\n",
        "ax[1].set_title('Convolved Image')\n",
        "ax[1].axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9df041d5",
      "metadata": {
        "id": "9df041d5"
      },
      "source": [
        "## 3. Creating a Filter for Edge Detection (5-10 min)\n",
        "In this section, we will explore edge detection using a Sobel filter. The Sobel filter is commonly used in edge detection and helps identify edges and gradients in an image."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Importing Resources and Displaying the Image"
      ],
      "metadata": {
        "id": "C0X_fXEO9aCq"
      },
      "id": "C0X_fXEO9aCq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "286f85cc",
      "metadata": {
        "id": "286f85cc"
      },
      "outputs": [],
      "source": [
        "# Load the image\n",
        "image_path = '02.1_sunflower_image.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Display the original and grayscale images\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "779d44c2",
      "metadata": {
        "id": "779d44c2"
      },
      "source": [
        "### 3.2 Creating and Applying a Sobel X Operator\n",
        "Now, we'll create a custom Sobel X operator and apply it to the grayscale image to detect edges in the x-direction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da0e1717",
      "metadata": {
        "id": "da0e1717"
      },
      "outputs": [],
      "source": [
        "# # Define the Sobel x operator\n",
        "# sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
        "\n",
        "# # Convert the Sobel x operator to a PyTorch tensor\n",
        "# sobel_x = torch.tensor(sobel_x, dtype=torch.float32)\n",
        "\n",
        "# # Apply the convolution using filter2D\n",
        "# filtered_image = cv2.filter2D(gray, -1, sobel_x.numpy())\n",
        "\n",
        "# # Display the filtered image\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.imshow(filtered_image, cmap='gray')\n",
        "# plt.title('Filtered Image (Sobel x)')\n",
        "# plt.axis('off')\n",
        "\n",
        "# plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad0a1ed9",
      "metadata": {
        "id": "ad0a1ed9"
      },
      "source": [
        "### 3.4 Testing Other Filters\n",
        "Feel free to create and test other filters to see different effects on the image. For example, you can create filters with decimal value weights or try a 5x5 filter."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60dfb844",
      "metadata": {
        "id": "60dfb844"
      },
      "source": [
        "## 4. Exercise: Custom Kernel for Feature Extraction (15 min)\n",
        "For this exercise, you'll define your custom kernel to perform feature extraction. Experiment with different kernel values to see how they affect the feature map. Ensure that the sum of the kernel values is between 0 and 1 for best results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edd874b6"
      },
      "outputs": [],
      "source": [
        "# Define your custom kernel with 3 rows and 3 columns\n",
        "# kernel = torch.tensor(...], dtype=torch.float32)\n",
        "\n",
        "# Display the kernel\n",
        "# print(kernel)\n"
      ],
      "id": "edd874b6"
    },
    {
      "cell_type": "markdown",
      "id": "b158a63c",
      "metadata": {
        "id": "b158a63c"
      },
      "source": [
        "Now, let's define our custom filters for edge detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eac079a8",
      "metadata": {
        "id": "eac079a8"
      },
      "outputs": [],
      "source": [
        "# Custom edge detection filter with decimal value weights\n",
        "# custom_filter_decimal = np.array([])\n",
        "\n",
        "# Custom 5x5 edge detection filter\n",
        "# custom_filter_5x5 = np.array([])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b68ed8ae",
      "metadata": {
        "id": "b68ed8ae"
      },
      "outputs": [],
      "source": [
        "# Load the image\n",
        "# image_path = ''\n",
        "# image = cv2.imread(image_path)\n",
        "\n",
        "# Define the custom filters as PyTorch tensors\n",
        "# custom_filter_decimal = torch.tensor(...)\n",
        "# custom_filter_5x5 = torch.tensor(...)\n",
        "\n",
        "# Apply the custom filters using filter2D\n",
        "# filtered_image_decimal = cv2.filter2D()\n",
        "# filtered_image_5x5 = cv2.filter2D()\n",
        "\n",
        "# Display the original and filtered images\n",
        "# plt.figure(figsize=(12, 8))\n",
        "# plt.subplot(1, 3, 1)\n",
        "# ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ef502d0",
      "metadata": {
        "id": "0ef502d0"
      },
      "source": [
        "Conclusion\n",
        "In this notebook, we explored the concepts of feature extraction and convolution in computer vision. We learned how to perform convolution using PyTorch and applied custom kernels for feature extraction. Understanding feature extraction is crucial for building effective computer vision models and can be a stepping stone for more complex tasks like object detection and segmentation. Experimenting with different kernels allows us to extract specific patterns and information from images, enabling us to gain insights and make better decisions in various applications."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References & resources"
      ],
      "metadata": {
        "id": "eyiUH2-T-PJs"
      },
      "id": "eyiUH2-T-PJs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "“[Understanding Convolution in Deep Learning](http://timdettmers.com/2015/03/26/convolution-deep-learning/)” Dettmers, Tim. TD Blog, 26 Mar 2015.\n",
        "“[Feature extraction using convolution](http://deeplearning.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/)” Ng, Andrew, Ngiam, Jiquan, Yu Foo, Chuan, Mai, Yifan, Suen, Caroline. UFLDL Tutorial. Stanford Deep Learning, 8 Apr 2013.\n",
        "- [The Scientist and Engineer’s Guide to Digital Signal Processing Smith, Steven](http://www.dspguide.com/pdfbook.htm). Copyright © 1997-1998\n",
        "\n",
        "- [Udacity Course](https://www.udacity.com/course/deep-learning-nanodegree--nd101):\n",
        "  - [GitHub](https://github.com/udacity/deep-learning-v2-pytorch/blob/master/convolutional-neural-networks) resources\n",
        "- CNN workshop: https://github.com/PracticumAI/cnn/tree/main\n",
        "- [Visualizing and Understanding Deep Neural Networks](https://www.youtube.com/watch?v=ghEmQSxT6tw) by Matt Zeiler\n",
        "- [Deep Learning in a Nutshell:](https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/) Core Concepts” Dettmers, Tim. Parallel For All. NVIDIA, 3 Nov 2015.\n",
        "\n",
        "[1] An Introduction to Convolutional Neural Networks https://arxiv.org/abs/1511.08458\n",
        "\n",
        "[2] Vincent Dumoulin, Francesco Visin - A guide to convolution arithmetic for deep learning https://arxiv.org/abs/1603.07285\n",
        "\n",
        "©2022 Shadi Albarqouni Lectures. Professor of Computational Medical Imaging Research at University of Bonn | AI Young Investigator Group Leader at Helmholtz AI"
      ],
      "metadata": {
        "id": "ivvx2iDb-YXW"
      },
      "id": "ivvx2iDb-YXW"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch-gpu",
      "language": "python",
      "name": "torch-gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}